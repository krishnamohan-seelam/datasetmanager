# Dataset Manager Platform

A high-performance, scalable platform designed for managing, analyzing, and securing large-scale datasets. This platform features a hybrid storage architecture, dynamic data masking, and a robust ETL pipeline.



**Note**: This is a work in progress, need to fix unit test failures also and I am using this project to learn about data engineering, data science, and software engineering.
---
## Tools used
- VSCODE + Github Copilot
- Google Antigravity
- Docker
- Docker Compose

---

##  Project Documentation

- **[Enhanced Product Requirements Document (PRD)](./Enhanced-PRD.md)**: Detailed specifications, system architecture, and project roadmap.
- **[Feature Progress Update](./FEATURE_PROGRESS_UPDATE.md)**: Current implementation status, completed milestones, and upcoming tasks.

---

*   **Dynamic Storage Engine**: Automatically creates per-dataset Cassandra tables with typed columns for optimized performance.
*   **Privacy-First Analytics**: Context-aware data masking (Email, SSN, Phone, CC) that automatically adapts based on user roles.
*   **Advanced Visualization**: Real-time data quality metrics and distributions powered by Recharts.
*   **Event-Driven Architecture**: Fully integrated with Apache Kafka for real-time audit logging and system events.
*   **Scalable ETL Pipeline**: Apache Airflow DAGs for automated dataset validation and ingestion.
*   **Multi-Backend Storage**: Support for AWS S3, local MinIO, and flat-file storage via a factory pattern.

---

## ğŸ“¸ Screenshots

| Dashboard Overview | Dataset Analytics |
|:---:|:---:|
| ![Homepage](./screenshots/homepage.jpeg) | ![Analytics](./screenshots/dataset_analytics.jpeg) |

| Data Preview & Masking | Schema Management |
|:---:|:---:|
| ![Preview](./screenshots/dataset_preview.jpeg) | ![Schema](./screenshots/dataset_schema.jpeg) |

---

## ğŸ› ï¸ Technical Stack

### **Backend**
- **Framework**: FastAPI (Python 3.10+)
- **Database**: Apache Cassandra (structured per-dataset tables)
- **Task Queue**: Apache Airflow
- **Messaging**: Apache Kafka
- **Caching**: Redis
- **Auth**: JWT with Bcrypt password hashing
- **Testing**: Pytest

### **Frontend**
- **Framework**: React 18 with TypeScript
- **State Management**: Redux Toolkit
- **UI Library**: Material UI (MUI)
- **Visuals**: Recharts
- **Form Handling**: React Hook Form + Zod
- **Build Tool**: Vite

---

## ğŸ“ Project Structure

```text
datasetmanager/
â”œâ”€â”€ dataset-manager/              # Backend (Python/FastAPI)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ core/                 # Security, Masking, Config
â”‚   â”‚   â”œâ”€â”€ services/             # Dataset, Permission, Pagination Cache
â”‚   â”‚   â”œâ”€â”€ schemas/              # Pydantic request/response models
â”‚   â”‚   â”œâ”€â”€ integrations/         # S3, Kafka, Redis, Local Storage
â”‚   â”‚   â”œâ”€â”€ middleware/           # Audit Logging, Rate Limiting
â”‚   â”‚   â”œâ”€â”€ monitoring/           # Prometheus Metrics, Grafana Config
â”‚   â”‚   â”œâ”€â”€ utils/                # Shared helpers
â”‚   â”‚   â””â”€â”€ main.py              # FastAPI app & route definitions
â”‚   â”œâ”€â”€ airflow/dags/             # Airflow ETL pipeline DAGs
â”‚   â”œâ”€â”€ scripts/                  # DB migration & init scripts
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ unit/                 # Unit tests (services, cache)
â”‚   â”‚   â”œâ”€â”€ integration/          # Integration tests (Release 2)
â”‚   â”‚   â””â”€â”€ performance_benchmarks.py
â”‚   â”œâ”€â”€ pyproject.toml            # Single dependency manifest
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ frontend/                     # Frontend (React/TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/                  # Axios client & endpoint wrappers
â”‚   â”‚   â”œâ”€â”€ components/           # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/                # Views (List, Detail, Upload, Analytics)
â”‚   â”‚   â”œâ”€â”€ store/                # Redux Toolkit slices & hooks
â”‚   â”‚   â”œâ”€â”€ types/                # TypeScript type definitions
â”‚   â”‚   â””â”€â”€ theme/                # MUI theme customization
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ Planning/                     # Architecture & design docs
â”œâ”€â”€ Enhanced-PRD.md               # Product Requirements Document
â”œâ”€â”€ FEATURE_PROGRESS_UPDATE.md    # Release progress tracker
â””â”€â”€ README.md
```

---

## ğŸ³ Docker Capability

The entire platform is containerized and can be launched with a single command. This includes the application services (Backend & Frontend) and all infrastructure dependencies.

### **Quick Start with Docker**
1.  **Build and Start**:
    ```bash
    docker-compose up --build -d
    ```
2.  **Initialize Database**:
    Wait for Cassandra to be healthy (approx. 60s), then run:
    ```bash
    docker-compose exec fastapi poetry run python scripts/init_cassandra.py
    ```

### **Service Access**
| Service | URL | Note |
|:---|:---|:---|
| **Frontend** | `http://localhost:5173` | Main Web UI |
| **API Backend** | `http://localhost:8000` | API Documentation at `/docs` |
| **MinIO Console**| `http://localhost:9001` | Object Storage Browser |
| **Cassandra** | `localhost:9042` | Primary Database |
| **Redis** | `localhost:6379` | Cache Layer |
| **Kafka** | `localhost:9092` | Event Streaming |

---

## ğŸš¦ Local Development (Manual)

### **Prerequisites**
- Python 3.10+ & Poetry
- Node.js 18+ & npm
- Docker (for infrastructure only)

### **1. Infrastructure Setup**
Start only the dependencies (Cassandra, Kafka, Redis, MinIO):
```bash
docker-compose up -d cassandra kafka redis minio
```

### **2. Backend Setup**
```bash
cd dataset-manager
poetry install
# Initialize Cassandra schema
poetry run python scripts/init_cassandra.py
# Run the application
poetry run uvicorn app.main:app --reload
```

### **3. Frontend Setup**
```bash
cd frontend
npm install
npm run dev
```
The application will be available at `http://localhost:5173`.

---

## ğŸ›¡ï¸ Security & Privacy

This platform implements a robust security model:
- **RBAC**: Role-Based Access Control (Admin, Owner, Viewer).
- **Data Masking**: Automatic redacting of sensitive fields for non-admin users.
- **Audit Trails**: Every data access and modification is logged to Kafka for compliance.
- **Rate Limiting**: Integrated middleware to prevent brute-force and API abuse.

---

## âš–ï¸ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
